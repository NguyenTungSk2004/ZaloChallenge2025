import cv2
import os
import numpy as np
from queue import Queue
import threading

def extract_frames_to_queue(
    video_path: str,
    base_fps: float = 2,
    high_fps: float = 10,
    motion_threshold: float = 30,
    motion_persist_time: float = 1.5,
    frame_diff_interval: int = 1,
    max_queue_size: int = 100
) -> Queue:
    """
    TrÃ­ch xuáº¥t frame tá»« video, tÄƒng tá»‘c khi cÃ³ chuyá»ƒn Ä‘á»™ng, vÃ  Ä‘Æ°a vÃ o hÃ ng Ä‘á»£i (queue).

    Args:
        video_path (str): ÄÆ°á»ng dáº«n video.
        base_fps (float): FPS khi khÃ´ng cÃ³ chuyá»ƒn Ä‘á»™ng.
        high_fps (float): FPS khi cÃ³ chuyá»ƒn Ä‘á»™ng.
        motion_threshold (float): NgÆ°á»¡ng phÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng (Ä‘á»™ chÃªnh lá»‡ch pixel trung bÃ¬nh).
        motion_persist_time (float): Thá»i gian duy trÃ¬ high_fps sau khi háº¿t chuyá»ƒn Ä‘á»™ng.
        frame_diff_interval (int): Khoáº£ng so sÃ¡nh frame Ä‘á»ƒ tÃ­nh biáº¿n thiÃªn.
        max_queue_size (int): KÃ­ch thÆ°á»›c tá»‘i Ä‘a cá»§a queue.

    Returns:
        queue.Queue: HÃ ng Ä‘á»£i chá»©a cÃ¡c frame (numpy.ndarray).
    """

    q = Queue(maxsize=max_queue_size)

    def worker():
        if not os.path.exists(video_path):
            print(f"âŒ Video khÃ´ng tá»“n táº¡i: {video_path}")
            q.put(None)
            return

        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        if not cap.isOpened() or fps == 0:
            print(f"âŒ KhÃ´ng thá»ƒ má»Ÿ video hoáº·c láº¥y FPS: {video_path}")
            q.put(None)
            return

        frame_interval = int(max(1, fps / base_fps))
        high_frame_interval = int(max(1, fps / high_fps))

        prev_gray = None
        frame_id = 0
        motion_mode = False
        motion_countdown = 0

        print(f"ðŸŽžï¸ Xá»­ lÃ½ video {os.path.basename(video_path)} | FPS gá»‘c: {fps:.1f}")

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            frame_id += 1
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            if prev_gray is not None and frame_id % frame_diff_interval == 0:
                diff = cv2.absdiff(gray, prev_gray)
                motion_score = np.mean(diff)

                if motion_score > motion_threshold:
                    motion_mode = True
                    motion_countdown = int(fps * motion_persist_time)
                else:
                    motion_countdown -= 1
                    if motion_countdown <= 0:
                        motion_mode = False

                interval = high_frame_interval if motion_mode else frame_interval

                if frame_id % interval == 0:
                    if not q.full():
                        print("âœ… ÄÆ°a vÃ o queue:", frame_id)
                        q.put(frame.copy())  # copy Ä‘á»ƒ trÃ¡nh lá»—i bá»™ nhá»›
                    else:
                        print("âš ï¸ Queue Ä‘áº§y, bá» qua frame")

            prev_gray = gray

        cap.release()
        q.put(None)  # bÃ¡o hiá»‡u káº¿t thÃºc video
        print(f"âœ… HoÃ n táº¥t: {os.path.basename(video_path)}")

    # cháº¡y trong thread riÃªng Ä‘á»ƒ queue nháº­n frame báº¥t Ä‘á»“ng bá»™
    threading.Thread(target=worker, daemon=True).start()

    return q
